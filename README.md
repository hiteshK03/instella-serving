# Instella Serving

Scripts to serve and run the Instella model using vLLM with necessary patches.

## Files

- `serve_instella.py`: Launches a vLLM API server with Instella patches.
- `run_instella.py`: Example script to run Instella with vLLM directly.
- `utils.py`: Contains the patching logic for vLLM and Transformers compatibility.

## Usage

1. Install requirements (vLLM, transformers, torch, etc.)
2. Run `python serve_instella.py`
